{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.tasks import process_deep_entries_data\n",
    "from core.helpers.common import rm_punc_not_nums, rm_stop_words_txt, translate_to_english_txt, compose\n",
    "from core.classifiers.feature_selector import DocumentFeatureSelector, BigramFeatureSelector\n",
    "from core.classifiers.NaiveBayes_classifier import NaiveBayesClassifier\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import random\n",
    "import langid\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING DEEP ENTRIES DATA\n",
      "DONE\n",
      "REMOVING PUNC AND STOP WORDS\n",
      "DONE\n",
      "SHUFFLING DATA\n",
      "DONE\n",
      "TAKING OUT TEST/TRAIN DATA\n",
      "length of training data 90\n",
      "DONE\n",
      "COUNTING TAG FREQUENCIES in TRAIN DATA\n",
      "{'WASH': 7, 'Food': 16, 'Nutrition': 11, 'Health': 10, 'NFI': 4, 'Livelihood': 10, 'Protection': 8, 'Shelter': 9, 'Education': 4, 'Agriculture': 2, 'Cross': 4, 'Logistic': 5}\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = '_playground/sample_data/nlp_out.csv'\n",
    "\n",
    "print('PROCESSING DEEP ENTRIES DATA')\n",
    "data = process_deep_entries_data(csv_file_path)[:150]\n",
    "print('DONE')\n",
    "\n",
    "print('REMOVING PUNC AND STOP WORDS')\n",
    "stemmer = SnowballStemmer('english')\n",
    "rm_punc_and_stop = compose(\n",
    "    rm_punc_not_nums,\n",
    "    rm_stop_words_txt,\n",
    "    stemmer.stem # comment this if we don't need stemming\n",
    ")\n",
    "data = [(rm_punc_and_stop(str(ex)), l) for (ex, l) in data if langid.classify(str(ex))[0] == 'en']\n",
    "print('DONE')\n",
    "\n",
    "print('SHUFFLING DATA')\n",
    "random.shuffle(data)\n",
    "print('DONE')\n",
    "\n",
    "data_len = len(data)\n",
    "test_len = int(data_len * 0.4)\n",
    "\n",
    "print('TAKING OUT TEST/TRAIN DATA')\n",
    "train_data = data[test_len:]\n",
    "print(\"length of training data\", len(train_data))\n",
    "test_data = data[:test_len]\n",
    "print('DONE')\n",
    "\n",
    "print('COUNTING TAG FREQUENCIES in TRAIN DATA')\n",
    "d = {}\n",
    "for ex, l in train_data:\n",
    "    d[l] = d.get(l, 0) + 1\n",
    "print(d)\n",
    "print('DONE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING FEATURE SELECTOR\n",
      "DONE\n",
      "CREATING CLASSIFIER\n",
      "DONE\n",
      "ACCURACY 0.1694915254237288\n",
      "CONFUSION MATRIX\n",
      "           |              L           P       |\n",
      "           |     E        i        N  r       |\n",
      "           |     d        v  L     u  o       |\n",
      "           |     u        e  o     t  t  S    |\n",
      "           |     c     H  l  g     r  e  h    |\n",
      "           |  C  a     e  i  i     i  c  e    |\n",
      "           |  r  t  F  a  h  s     t  t  l  W |\n",
      "           |  o  i  o  l  o  t  N  i  i  t  A |\n",
      "           |  s  o  o  t  o  i  F  o  o  e  S |\n",
      "           |  s  n  d  h  d  c  I  n  n  r  H |\n",
      "-----------+----------------------------------+\n",
      "     Cross | <.> .  4  .  .  .  .  .  .  .  . |\n",
      " Education |  . <.> 1  .  .  .  .  .  .  .  . |\n",
      "      Food |  .  .<10> .  .  .  .  .  .  .  . |\n",
      "    Health |  .  .  5 <.> .  .  .  .  .  .  . |\n",
      "Livelihood |  .  .  6  . <.> .  .  .  .  .  . |\n",
      "  Logistic |  .  .  1  .  . <.> .  .  .  .  . |\n",
      "       NFI |  .  .  3  .  .  . <.> .  .  .  . |\n",
      " Nutrition |  .  .  7  .  .  .  . <.> .  .  . |\n",
      "Protection |  .  . 12  .  .  .  .  . <.> .  . |\n",
      "   Shelter |  .  .  5  .  .  .  .  .  . <.> . |\n",
      "      WASH |  .  .  5  .  .  .  .  .  .  . <.>|\n",
      "-----------+----------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('CREATING FEATURE SELECTOR')\n",
    "# print(freq_words[:200])\n",
    "# assert False\n",
    "selector = DocumentFeatureSelector.new(corpus=data)\n",
    "print('DONE')\n",
    "\n",
    "# print('CREATING BIGRAM FEATURE SELECTOR')\n",
    "# selector = BigramFeatureSelector.new(corpus=data, top=2000)\n",
    "# selector = DocumentFeatureSelector.new(corpus=data, top=2000)\n",
    "# print('DONE')\n",
    "\n",
    "print('CREATING CLASSIFIER')\n",
    "classifier = NaiveBayesClassifier.new(selector, rm_punc_and_stop, train_data)\n",
    "print('DONE')\n",
    "\n",
    "print('ACCURACY', classifier.get_accuracy(test_data))\n",
    "\n",
    "print('CONFUSION MATRIX')\n",
    "print(classifier.get_confusion_matrix(test_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (.env)",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
